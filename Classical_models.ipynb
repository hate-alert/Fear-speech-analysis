{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:07:16.300209Z",
     "start_time": "2020-09-26T09:07:16.126647Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook,tqdm\n",
    "import numpy as np\n",
    "import demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix,make_scorer, f1_score, accuracy_score, recall_score, precision_score, roc_auc_score,classification_report, precision_recall_fscore_support\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_classification_report(y_true, y_pred):\n",
    "    metrics_summary = precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    avg = list(precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred,\n",
    "            average='macro'))\n",
    "    avg.append(accuracy_score(y_true, y_pred, normalize=True))\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support','accuracy']\n",
    "    list_all=list(metrics_summary)\n",
    "    list_all.append(cm.diagonal())\n",
    "    class_report_df = pd.DataFrame(\n",
    "        list_all,\n",
    "        index=metrics_sum_index)\n",
    "\n",
    "    support = class_report_df.loc['support']\n",
    "    total = support.sum() \n",
    "    avg[-2] = total\n",
    "\n",
    "    class_report_df['avg / total'] = avg\n",
    "\n",
    "    return class_report_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path='Data/'\n",
    "\n",
    "import json\n",
    "with open(parent_path+'fear_speech_data.json', 'r') as fp:\n",
    "    fear_speech_data=json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_text': '*à¤ªà¥à¤°à¤¶à¤¾à¤¸à¤• à¤¸à¤®à¤¿à¤¤à¤¿*âœŠðŸš©  â—â—â—â—â—â—â—â—â—â—â— â— â— â— ðŸ˜ŽðŸš© *à¤†à¤‚à¤¤à¤•à¤µà¤¾à¤¦à¥€ à¤¸à¤‚à¤—à¤ à¤¨à¥‹à¤‚ à¤•à¤¾ðŸ’£ðŸ”ª à¤‡à¤¸à¥à¤²à¤¾à¤®à¤¿à¤• à¤¨à¤¾à¤® à¤”à¤° à¤‰à¤¨à¤•à¤¾ à¤‡à¤¸à¥à¤²à¤¾à¤®.....* *à¤§à¤°à¥à¤® à¤¸à¥‡ à¤œà¥à¥œà¤¾ à¤¹à¥à¤† à¤…à¤°à¥à¤¥...* ðŸ–ðŸ–ðŸ– *1.à¤²à¤¶à¥à¤•à¤°à¥‡ à¤¤à¥ˆà¤¯à¤¬à¤¾-à¤«à¤°à¤¿à¤¶à¥à¤¤à¥‹ à¤•à¥€ à¤¸à¥‡à¤¨à¤¾* *2.à¤…à¤² à¤•à¤¾à¤¯à¤¦à¤¾-à¤…à¤²à¥à¤²à¤¾à¤¹ à¤•à¤¾ à¤•à¤¾à¤¯à¤¦à¤¾...* *3.à¤œà¥‡à¤¶ à¤ à¤®à¥‹à¤¹à¤®à¥à¤¦-à¤®à¥‹à¤¹à¤®à¥à¤®à¤¦ à¤¸à¤¾à¤¹à¥‡à¤¬ à¤•à¤¾ à¤¦à¤²...* *4.à¤¤à¤¹à¤°à¤¿à¤• à¤ à¤¤à¤¾à¤²à¤¿à¤¬à¤¾à¤¨-à¤ªà¤µà¤¿à¤¤à¥à¤° à¤¯à¥‹à¤¦à¥à¤§à¤¾à¤“ à¤•à¤¾ à¤¦à¤²...* *5.à¤¹à¤¿à¤œà¤¬à¥à¤² à¤®à¥à¤œà¤¾à¤¦à¤¿à¤¨-à¤‡à¤¸à¥à¤²à¤¾à¤®à¥€ à¤¬à¤²à¤¿à¤¦à¤¾à¤¨à¤¿à¤¯à¥‹ à¤•à¤¾ à¤¸à¤®à¥‚à¤¹...* *6.à¤¬à¥‹à¤•à¥‹ à¤¹à¤°à¤¾à¤® -à¤ªà¥ˆà¤—à¤®à¥à¤¬à¤° à¤®à¥à¤¹à¤®à¥à¤®à¤¦ à¤•à¥€ à¤¶à¤¿à¤•à¥à¤·à¤¾ à¤•à¥‹ à¤«à¥ˆà¤²à¤¾à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤ªà¥à¤°à¤¤à¤¿à¤¬à¤¦à¥à¤§..* *à¤¸à¤­à¥€ à¤®à¥à¤¸à¥à¤²à¤®à¤¾à¤¨ à¤…à¤œà¥à¤žà¤¾à¤¨à¤¿ à¤…à¤²à¥à¤²à¤¾à¤¹ à¤•à¥€ à¤¬à¤¤à¤¾à¤ˆ à¤¹à¥à¤ˆ à¤°à¥‚à¤¹à¤¾à¤¨à¥€ à¤•à¤¿à¤¤à¤¾à¤¬ à¥˜à¥à¤°à¤†à¤¨ à¤•à¥€ à¤¬à¤¤à¤¾à¤ˆ à¤°à¤¾à¤¹* *(à¤ªà¥‚à¤°à¥€ à¤¦à¥à¤¨à¤¿à¤¯à¤¾ à¤•à¥‹ à¤‡à¤¸à¥à¤²à¤¾à¤® à¤¬à¤¨à¤¾à¤¨à¤¾)à¤ªà¤° à¤¹à¥€ à¤šà¤² à¤°à¤¹à¥‡ à¤¹à¥ˆ à¤•à¥‹à¤ˆ à¤œà¥à¤¯à¤¾à¤¦à¤¾ à¤¬à¤šðŸ‘¨\\u200dðŸ‘¨\\u200dðŸ‘¦* *à¤ªà¥ˆà¤¦à¤¾ à¤•à¤°à¤•à¥‡ à¤¤à¥‹ à¤•à¥‹à¤ˆ à¤²à¤µ à¤œà¤¿à¤¹à¤¾à¤¦ðŸ‘« à¤•à¤°à¤•à¥‡ à¤¤à¥‹ à¤•à¥‹à¤ˆ à¤•à¤¾à¥žà¤¿à¤°(à¤—à¥‡à¤° à¤®à¥à¤¸à¤²à¤®à¤¾à¤¨)à¤•à¥‹ à¤®à¤¾à¤°à¤•à¤°..* *à¤§à¤°à¤¤à¥€ à¤ªà¤° à¤†à¤‚à¤¤à¤•ðŸ”«ðŸ’£ðŸ’£ðŸ’£ðŸ”«à¤«à¥‡à¤²à¤¾ à¤°à¤¹à¥‡ à¤¹à¥ˆ\\ufeffà¥¤à¥¤* ðŸ˜¡ðŸ˜¡ðŸ˜¡ðŸ˜ŽðŸ˜¡ðŸ˜¡ðŸ˜¡  *à¤œà¤¯ à¤¸à¤¨à¤¾à¤¤à¤¨ à¤§à¤°à¥à¤® à¤•à¥€*ðŸš©ðŸš©ðŸš©  ðŸ™ðŸš©ðŸ‡®ðŸ‡³ðŸ”±ðŸ¹ðŸšðŸ•‰',\n",
       " 'translated_text': '* Administrator âœŠ ðŸš©   Committee * â— â—â—â—â—â—â—â—â—â—â— ðŸš©  ðŸ˜Ž  â— â— â— à¤¨à¤¾à¤® ðŸ”ª  ðŸ’£  * Islamic name of terrorist organizations and their meaning ðŸ–  ðŸ–  ðŸ–  in Islamâ€¦ .. * Religionâ€¦ * ... 1. * 1. Army of Lashkar-e-Taiba-Farishto * * 2. Al Qaeda-Qaeda of Allah ... * * 3. Team of Jesh-e-Mohammad-Mohammed Saheb ... * * 4. Tahrik-e-Taliban-Holy Warriors Party ... * * 5. Hijbul Mujadin-group of Islamic sacrifices ... * * 6. Boko Haram - Committed to spread the teachings of Prophet Muhammad .. * * All the Muslim ignorance told the Quran of Allah the ðŸ‘¨ ðŸ‘¦   ðŸ‘¨  spiritual book The path ðŸ‘«  is going on * (making the whole world Islam), by creating ðŸ”«  ðŸ’£  ðŸ’£  ðŸ’£  ðŸ”« ðŸ˜¡ ðŸ˜¡ ðŸ˜¡ ðŸ˜¡  ðŸ˜¡   ðŸ˜Ž   ðŸ˜¡    some ðŸš© ðŸš©  ðŸ™ ðŸ‡® ðŸ”± ðŸš ðŸ•‰   ðŸ¹   ðŸ‡³   ðŸš©   ðŸš©   more children * * *, by creating some love jihad and by killing a kafir (Ger Muslim) .. * * Terror on Earth ðŸ’£ðŸ’£ðŸ’£ðŸ”«Fella is there. * ðŸ˜¡ðŸ˜¡ðŸ˜¡ðŸ˜ŽðŸ˜¡ðŸ˜¡ðŸ˜¡ * Jai of Sanatan Dharma * ðŸš©ðŸš©ðŸš© ðŸ™ðŸš©ðŸ‡®ðŸ‡³ðŸ”±ðŸ¹ðŸšðŸ•‰  ',\n",
       " 'annotation_list': ['Fear speech', 'Fear speech', 'Normal'],\n",
       " 'propagation': [{'group_id': 9087,\n",
       "   'user_id': 229869,\n",
       "   'timestamp': 1538130086000},\n",
       "  {'group_id': 7, 'user_id': 215, 'timestamp': 1550186113000}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fear_speech_data['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00b0ce0b4cc419987c1b50f4977c81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocess import *\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "list_sents = []\n",
    "list_labels=[]\n",
    "for key in tqdm_notebook(fear_speech_data.keys(),total=len(fear_speech_data)):\n",
    "    element = fear_speech_data[key]\n",
    "    \n",
    "    count_fearspeech=element['annotation_list'].count('Fear speech')\n",
    "    count_normal=element['annotation_list'].count('Normal')\n",
    "    \n",
    "    if(count_fearspeech>count_normal):\n",
    "        one_fear_speech=1\n",
    "    else:\n",
    "        one_fear_speech=0\n",
    "    \n",
    "    text=preprocess_sent(element['message_text'],params={'remove_numbers': True, 'remove_emoji': True, 'remove_stop_words': False, 'tokenize': True})\n",
    "    list_sents.append(text)\n",
    "    list_labels.append(one_fear_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = np.array(list_sents,dtype='object')\n",
    "y_0 = np.array(list_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_run(model_name='lr'):\n",
    "    acc=[]\n",
    "    macro_f1=[]\n",
    "    prec=[]\n",
    "    recall=[]\n",
    "    prob=[]\n",
    "    auc_roc=[]\n",
    "    list_total_preds=[]\n",
    "    list_total_truth=[]\n",
    "    skf = StratifiedKFold(n_splits=5, random_state= 2020)\n",
    "\n",
    "    for train_index, test_index in skf.split(X_0, y_0):\n",
    "        print(\"TRAIN:\", train_index[0:5], \"TEST:\", test_index[0:5])\n",
    "        X_train, X_test = X_0[train_index], X_0[test_index]\n",
    "        y_train, y_test = y_0[train_index], y_0[test_index]\n",
    "\n",
    "        class_weights = dict(zip(np.unique(y_train), compute_class_weight(\"balanced\", np.unique(y_train),y_train)))\n",
    "\n",
    "\n",
    "        print(class_weights)\n",
    "        ### Generate doc2vec vectors\n",
    "        documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train)]\n",
    "        model = Doc2Vec(documents, vector_size=300, window=5, min_count=1, workers=10)\n",
    "        X_train_embed = np.array([list(model.infer_vector(ele)) for ele in X_train])\n",
    "        X_test_embed = np.array([list(model.infer_vector(ele)) for ele in X_test])\n",
    "        \n",
    "        if(model_name=='lr'):\n",
    "            classifier= LogisticRegression(class_weight='balanced',max_iter=500)\n",
    "        \n",
    "        elif(model_name=='svc'):\n",
    "            classifier=SVC(class_weight='balanced',kernel='rbf',probability=True)\n",
    "        \n",
    "        classifier.fit(X_train_embed, y_train)\n",
    "        y_pred=classifier.predict(X_test_embed)\n",
    "        y_pred_proba = classifier.predict_proba(X_test_embed)\n",
    "        acc.append(accuracy_score(y_test, y_pred))\n",
    "        macro_f1.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        auc_roc.append(roc_auc_score(y_test, y_pred_proba[:,1],average='macro'))\n",
    "        prec.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        prob.append(classifier.predict_proba(X_test_embed))\n",
    "        list_total_preds+=list(y_pred)\n",
    "        list_total_truth+=list(y_test)\n",
    "    return acc, macro_f1, prec, prob,auc_roc,list_total_preds,list_total_truth,prec,recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [870 872 873 874 875] TEST: [0 1 2 3 4]\n",
      "{0: 0.6567651098901099, 1: 2.0947426067907995}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 1 2 3 4] TEST: [870 872 873 874 875]\n",
      "{0: 0.6567651098901099, 1: 2.0947426067907995}\n",
      "TRAIN: [0 1 2 3 4] TEST: [1771 1772 1773 1774 1775]\n",
      "{0: 0.6569368131868132, 1: 2.0929978118161925}\n",
      "TRAIN: [0 1 2 3 4] TEST: [2757 2758 2759 2761 2762]\n",
      "{0: 0.6569368131868132, 1: 2.0929978118161925}\n",
      "TRAIN: [0 1 2 3 4] TEST: [3792 3794 3796 3799 3801]\n",
      "{0: 0.6569368131868132, 1: 2.0929978118161925}\n",
      "Accuracy: 0.75 (+/- 0.07)\n",
      "Macro F1: 0.68 (+/- 0.06)\n",
      "Auc Roc F1: 0.77 (+/- 0.07)\n",
      "Precision for +ve class: 0.50 (+/- 0.16)\n",
      "Recall for +ve class: 0.60 (+/- 0.13)\n",
      "             precision    recall  f1-score  support  accuracy\n",
      "0             0.864512  0.801099  0.831598   3640.0  0.801099\n",
      "1             0.486160  0.599825  0.537044   1142.0  0.599825\n",
      "avg / total   0.675336  0.700462  0.684321   4782.0  0.753032\n"
     ]
    }
   ],
   "source": [
    "acc, macro_f1, prec, prob,auc_roc,list_total_preds,list_total_truth,prec,recall=model_run(model_name='svc')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (np.mean(acc), np.std(acc) * 2))\n",
    "print(\"Macro F1: %0.2f (+/- %0.2f)\" % (np.mean(macro_f1), np.std(macro_f1) * 2))\n",
    "print(\"Auc Roc F1: %0.2f (+/- %0.2f)\" % (np.mean(auc_roc), np.std(auc_roc) * 2))\n",
    "print(\"Precision for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(prec), np.std(prec) * 2))\n",
    "print(\"Recall for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(recall), np.std(recall) * 2))\n",
    "print(pandas_classification_report(list_total_truth, list_total_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [870 872 873 874 875] TEST: [0 1 2 3 4]\n",
      "{0: 0.6567651098901099, 1: 2.0947426067907995}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 1 2 3 4] TEST: [870 872 873 874 875]\n",
      "{0: 0.6567651098901099, 1: 2.0947426067907995}\n",
      "TRAIN: [0 1 2 3 4] TEST: [1771 1772 1773 1774 1775]\n",
      "{0: 0.6569368131868132, 1: 2.0929978118161925}\n",
      "TRAIN: [0 1 2 3 4] TEST: [2757 2758 2759 2761 2762]\n",
      "{0: 0.6569368131868132, 1: 2.0929978118161925}\n",
      "TRAIN: [0 1 2 3 4] TEST: [3792 3794 3796 3799 3801]\n",
      "{0: 0.6569368131868132, 1: 2.0929978118161925}\n",
      "Accuracy: 0.73 (+/- 0.08)\n",
      "Macro F1: 0.67 (+/- 0.07)\n",
      "Auc Roc: 0.76 (+/- 0.08)\n",
      "Precision for +ve class: 0.47 (+/- 0.15)\n",
      "Recall for +ve class: 0.60 (+/- 0.14)\n",
      "             precision    recall  f1-score  support  accuracy\n",
      "0             0.861543  0.776099  0.816592   3640.0  0.776099\n",
      "1             0.457751  0.602452  0.520227   1142.0  0.602452\n",
      "avg / total   0.659647  0.689275  0.668409   4782.0  0.734630\n"
     ]
    }
   ],
   "source": [
    "acc, macro_f1, prec, prob,auc_roc,list_total_preds,list_total_truth,prec,recall=model_run(model_name='lr')\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (np.mean(acc), np.std(acc) * 2))\n",
    "print(\"Macro F1: %0.2f (+/- %0.2f)\" % (np.mean(macro_f1), np.std(macro_f1) * 2))\n",
    "print(\"Auc Roc: %0.2f (+/- %0.2f)\" % (np.mean(auc_roc), np.std(auc_roc) * 2))\n",
    "print(\"Precision for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(prec), np.std(prec) * 2))\n",
    "print(\"Recall for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(recall), np.std(recall) * 2))\n",
    "print(pandas_classification_report(list_total_truth, list_total_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-punyajoy_gpu] *",
   "language": "python",
   "name": "conda-env-.conda-punyajoy_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
